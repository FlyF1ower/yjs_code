{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import FlavaModel, FlavaProcessor\n",
    "\n",
    "\n",
    "# ===============存储文本、视觉、多模态分支的结果===============\n",
    "text_q = [] # 各层自注意力的key和query\n",
    "text_k = []\n",
    "vision_q = []\n",
    "vision_k = []\n",
    "multimodal_q = []\n",
    "multimodal_k = []\n",
    "\n",
    "# text_ffn_outputs = [] # 各层FFN的输出\n",
    "# vision_ffn_outputs = []\n",
    "# multimodal_ffn_outputs = []\n",
    "\n",
    "# image_embedding_before_transformer = None   \n",
    "# text_embedding_before_transformer = None\n",
    "# multi_embedding_before_transformer = None\n",
    "\n",
    "hooks = []  # 用于保存钩子以便移除\n",
    "\n",
    "# 定义钩子函数\n",
    "def register_hooks(encoder, modality):\n",
    "    encoder_hooks = []\n",
    "    num_layers = len(encoder.layer)\n",
    "\n",
    "    if modality == \"text\":\n",
    "        target_q, target_k = text_q, text_k\n",
    "    elif modality == \"vision\":\n",
    "        target_q, target_k = vision_q, vision_k\n",
    "    elif modality == \"multimodal\":\n",
    "        target_q, target_k = multimodal_q, multimodal_k\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown modality: {modality}\")\n",
    "    \n",
    "    while len(target_q) < num_layers:\n",
    "        target_q.append([])\n",
    "        target_k.append([])\n",
    "\n",
    "    for layer_idx, layer in enumerate(encoder.layer):\n",
    "        # 注册 SelfAttention 钩子\n",
    "        attn = layer.attention.attention\n",
    "        transpose_for_scores = attn.transpose_for_scores\n",
    "\n",
    "        # 注册 key 的钩子\n",
    "        def hook_key(module, input, output, layer_idx=layer_idx):\n",
    "            key_layer = transpose_for_scores(output)\n",
    "            key_layer = key_layer.cpu().numpy()\n",
    "            \n",
    "            target_k[layer_idx].append(key_layer)\n",
    "\n",
    "        # 注册 query 的钩子\n",
    "        def hook_query(module, input, output, layer_idx=layer_idx):\n",
    "            query_layer = transpose_for_scores(output)\n",
    "            query_layer = query_layer.cpu().numpy()\n",
    "\n",
    "            target_q[layer_idx].append(query_layer)\n",
    "        \n",
    "        encoder_hooks.append(attn.key.register_forward_hook(hook_key))\n",
    "        encoder_hooks.append(attn.query.register_forward_hook(hook_query))\n",
    "\n",
    "    return encoder_hooks\n",
    "\n",
    "\n",
    "def process_and_save(data_list, save_path, file_name):\n",
    "    \"\"\"\n",
    "        data_list维度是(layer, 1, batch, head, tokens, head_dim),\n",
    "        而这个第二个维度是无用的\n",
    "    \"\"\"\n",
    "    # 创建保存目录（如果不存在)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        print(f\"Directory {save_path} created.\")\n",
    "\n",
    "    # 检查 data_list 是否为空\n",
    "    if not data_list:\n",
    "        print(f\"No data to save for {file_name}.\")\n",
    "        return\n",
    "    \n",
    "    # 合并每个层的numpy数组\n",
    "    layer_arrays = []\n",
    "    for layer_data in data_list:\n",
    "        if layer_data:\n",
    "            layer_array = np.concatenate([t for t in layer_data], axis=0)\n",
    "            layer_arrays.append(layer_array)\n",
    "\n",
    "            del layer_data\n",
    "        else:\n",
    "            print(f\"Layer {len(layer_arrays)} has no data.\")\n",
    "\n",
    "    # 检查是否有层数据\n",
    "    if not layer_arrays:\n",
    "        print(f\"No layers to save for {file_name}.\")\n",
    "        return\n",
    "    \n",
    "    # 将所有层的数组沿第0维（层维度）堆叠成一个整体张量\n",
    "    all_layers_array  = np.stack(layer_arrays, axis=0)\n",
    "    # 保存为 NumPy 文件\n",
    "    save_file = os.path.join(save_path, f\"{file_name}_all_layers.npy\")\n",
    "    np.save(save_file, all_layers_array)\n",
    "    print(f\"Saved {save_file}\")\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ==========加载模型和分词器==========\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")                       # 设置设备\n",
    "    model_name = \"./model/facebook/flava-full\"     # 模型名称\n",
    "    model = FlavaModel.from_pretrained(model_name)  # 加载模型\n",
    "    processor = FlavaProcessor.from_pretrained(model_name)  # 加载分词器\n",
    "\n",
    "    # 模型加载至设备\n",
    "    model.to(device)\n",
    "    print(f\"模型已加载至 {device}\")\n",
    "\n",
    "    # 注册hooks\n",
    "    text_encoder = model.text_model.encoder\n",
    "    vision_encoder = model.image_model.encoder\n",
    "    multimodal_encoder = model.multimodal_model.encoder\n",
    "\n",
    "    hooks += register_hooks(text_encoder, modality=\"text\")\n",
    "    hooks += register_hooks(vision_encoder, modality=\"vision\")\n",
    "    hooks += register_hooks(multimodal_encoder, modality=\"multimodal\")\n",
    "\n",
    "\n",
    "    # ==========准备输入数据==========\n",
    "    # Text data\n",
    "    texts = []\n",
    "    texts_file_path = './stimulate_hcpmovie/text/movie1_modify.txt'\n",
    "    try:\n",
    "        with open(texts_file_path, 'r', encoding='utf-8') as file:\n",
    "            texts = [line.strip() for line in file.readlines()]\n",
    "            print(f\"Loaded {len(texts)} text lines.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {texts_file_path} not found.\")\n",
    "\n",
    "    # Image data\n",
    "    image_folder = './stimulate_hcpmovie/image/movie1'\n",
    "    images_list = os.listdir(image_folder)\n",
    "    images = [Image.open(os.path.join(image_folder, image)) for image in images_list]\n",
    "    print(f\"Loaded {len(images)} images.\")\n",
    "\n",
    "    input = processor(\n",
    "        text=texts,\n",
    "        images=images,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # 前向传播并捕获数据\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            pixel_values=input.pixel_values,\n",
    "            input_ids=input.input_ids\n",
    "        )\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "   # === Process and Save Data ===\n",
    "    process_and_save(text_q, './q', 'text_q')\n",
    "    process_and_save(text_k, './k', 'text_k')\n",
    "    process_and_save(vision_q, './q', 'vision_q')\n",
    "    process_and_save(vision_k, './k', 'vision_k')\n",
    "    process_and_save(multimodal_q, './q', 'multimodal_q')\n",
    "    process_and_save(multimodal_k, './k', 'multimodal_k')\n",
    "\n",
    "\n",
    "    # ==========清空存储==========\n",
    "    # 移除所有钩子\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    # 清空之前的存储\n",
    "    del text_q, text_k, vision_q, vision_k, multimodal_q, multimodal_k\n",
    "    print(\"Processing complete and memory cleared.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import FlavaModel, FlavaProcessor\n",
    "\n",
    "\n",
    "# ===============存储文本、视觉、多模态分支的结果===============\n",
    "text_q = [] # 各层自注意力的key和query\n",
    "text_k = []\n",
    "vision_q = []\n",
    "vision_k = []\n",
    "multimodal_q = []\n",
    "multimodal_k = []\n",
    "\n",
    "# text_ffn_outputs = [] # 各层FFN的输出\n",
    "# vision_ffn_outputs = []\n",
    "# multimodal_ffn_outputs = []\n",
    "\n",
    "# image_embedding_before_transformer = None   \n",
    "# text_embedding_before_transformer = None\n",
    "# multi_embedding_before_transformer = None\n",
    "\n",
    "hooks = []  # 用于保存钩子以便移除\n",
    "\n",
    "# 定义钩子函数\n",
    "def register_hooks(encoder, modality):\n",
    "    encoder_hooks = []\n",
    "    num_layers = len(encoder.layer)\n",
    "\n",
    "    if modality == \"text\":\n",
    "        target_q, target_k = text_q, text_k\n",
    "    elif modality == \"vision\":\n",
    "        target_q, target_k = vision_q, vision_k\n",
    "    elif modality == \"multimodal\":\n",
    "        target_q, target_k = multimodal_q, multimodal_k\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown modality: {modality}\")\n",
    "    \n",
    "    while len(target_q) < num_layers:\n",
    "        target_q.append([])\n",
    "        target_k.append([])\n",
    "\n",
    "    for layer_idx, layer in enumerate(encoder.layer):\n",
    "        # 注册 SelfAttention 钩子\n",
    "        attn = layer.attention.attention\n",
    "        transpose_for_scores = attn.transpose_for_scores\n",
    "\n",
    "        # 注册 key 的钩子\n",
    "        def hook_key(module, input, output, layer_idx=layer_idx):\n",
    "            key_layer = transpose_for_scores(output)\n",
    "            key_layer = key_layer.cpu().numpy()\n",
    "            \n",
    "            target_k[layer_idx].append(key_layer)\n",
    "\n",
    "        # 注册 query 的钩子\n",
    "        def hook_query(module, input, output, layer_idx=layer_idx):\n",
    "            query_layer = transpose_for_scores(output)\n",
    "            query_layer = query_layer.cpu().numpy()\n",
    "\n",
    "            target_q[layer_idx].append(query_layer)\n",
    "        \n",
    "        encoder_hooks.append(attn.key.register_forward_hook(hook_key))\n",
    "        encoder_hooks.append(attn.query.register_forward_hook(hook_query))\n",
    "\n",
    "    return encoder_hooks\n",
    "\n",
    "\n",
    "def process_and_save(data_list, save_path, file_name):\n",
    "    \"\"\"\n",
    "        data_list维度是(layer, 1, batch, head, tokens, head_dim),\n",
    "        而这个第二个维度是无用的\n",
    "    \"\"\"\n",
    "    # 创建保存目录（如果不存在)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        print(f\"Directory {save_path} created.\")\n",
    "\n",
    "    # 检查 data_list 是否为空\n",
    "    if not data_list:\n",
    "        print(f\"No data to save for {file_name}.\")\n",
    "        return\n",
    "    \n",
    "    # 合并每个层的numpy数组\n",
    "    layer_arrays = []\n",
    "    for layer_data in data_list:\n",
    "        if layer_data:\n",
    "            layer_array = np.concatenate([t for t in layer_data], axis=0)\n",
    "            layer_arrays.append(layer_array)\n",
    "\n",
    "            del layer_data\n",
    "        else:\n",
    "            print(f\"Layer {len(layer_arrays)} has no data.\")\n",
    "\n",
    "    # 检查是否有层数据\n",
    "    if not layer_arrays:\n",
    "        print(f\"No layers to save for {file_name}.\")\n",
    "        return\n",
    "    \n",
    "    # 将所有层的数组沿第0维（层维度）堆叠成一个整体张量\n",
    "    all_layers_array  = np.stack(layer_arrays, axis=0).transpose((1, 0, 2, 3, 4))\n",
    "    # 保存为 NumPy 文件\n",
    "    save_file = os.path.join(save_path, f\"{file_name}_all_layers.npy\")\n",
    "    np.save(save_file, all_layers_array)\n",
    "    print(f\"Saved {save_file}\")\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    output_dir = 'result_new'\n",
    "    movie = 'movie2'\n",
    "\n",
    "    # ==========加载模型和分词器==========\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")                       # 设置设备\n",
    "    device = \"cpu\"                    # 设置设备\n",
    "    model_name = \"./model/facebook/flava-full\"     # 模型名称\n",
    "    model = FlavaModel.from_pretrained(model_name)  # 加载模型\n",
    "    processor = FlavaProcessor.from_pretrained(model_name)  # 加载分词器\n",
    "\n",
    "    # 模型加载至设备\n",
    "    model.to(device)\n",
    "    print(f\"模型已加载至 {device}\")\n",
    "\n",
    "    # 注册hooks\n",
    "    text_encoder = model.text_model.encoder\n",
    "    vision_encoder = model.image_model.encoder\n",
    "    multimodal_encoder = model.multimodal_model.encoder\n",
    "\n",
    "    hooks += register_hooks(text_encoder, modality=\"text\")\n",
    "    hooks += register_hooks(vision_encoder, modality=\"vision\")\n",
    "    hooks += register_hooks(multimodal_encoder, modality=\"multimodal\")\n",
    "\n",
    "\n",
    "    # ==========准备输入数据==========\n",
    "    # Text data\n",
    "    texts = []\n",
    "    texts_file_path = './stimulate_hcpmovie/text/movie1_modify.txt'\n",
    "    try:\n",
    "        with open(texts_file_path, 'r', encoding='utf-8') as file:\n",
    "            texts = [line.strip() for line in file.readlines()]\n",
    "            print(f\"Loaded {len(texts)} text lines.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {texts_file_path} not found.\")\n",
    "\n",
    "    # Image data\n",
    "    image_folder = './stimulate_hcpmovie/image/movie1'\n",
    "    images_list = os.listdir(image_folder)\n",
    "    images = [Image.open(os.path.join(image_folder, image)) for image in images_list]\n",
    "    print(f\"Loaded {len(images)} images.\")\n",
    "\n",
    "    input = processor(\n",
    "        text=texts,\n",
    "        images=images,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # 前向传播并捕获数据\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            pixel_values=input.pixel_values,\n",
    "            input_ids=input.input_ids\n",
    "        )\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "   # === Process and Save Data ===\n",
    "    process_and_save(text_q, f'{output_dir}/{movie}/q', 'text_q')\n",
    "    process_and_save(text_k, f'{output_dir}/{movie}/k', 'text_k')\n",
    "    process_and_save(vision_q, f'{output_dir}/{movie}/q', 'vision_q')\n",
    "    process_and_save(vision_k, f'{output_dir}/{movie}/k', 'vision_k')\n",
    "    process_and_save(multimodal_q, f'{output_dir}/{movie}/q', 'multimodal_q')\n",
    "    process_and_save(multimodal_k, f'{output_dir}/{movie}/k', 'multimodal_k')\n",
    "\n",
    "\n",
    "    # ==========清空存储==========\n",
    "    # 移除所有钩子\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    # 清空之前的存储\n",
    "    del text_q, text_k, vision_q, vision_k, multimodal_q, multimodal_k\n",
    "    print(\"Processing complete and memory cleared.\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "movie = \"movie2\"\n",
    "modality = 'multimodal'\n",
    "\n",
    "# 加载Q, K\n",
    "Q = np.load(f'result_new/{movie}/q/{modality}_q_all_layers.npy')   # (sample, layer, head, sequence, head_dim)\n",
    "K = np.load(f'result_new/{movie}/k/{modality}_k_all_layers.npy')   # (sample, layer, head, sequence, head_dim)\n",
    "\n",
    "sample_num = Q.shape[0]    # 获取样本数\n",
    "layer_num = Q.shape[1] # 获取层数\n",
    "head_num = Q.shape[2]  # 获取头数\n",
    "head_dim = Q.shape[4]  # 获取每一个头的维度\n",
    "\n",
    "sample_neuron_activations = []\n",
    "for sample_id in range(sample_num):\n",
    "    if sample_id % 25 == 0 :\n",
    "        print(f\"====sample {sample_id}====\")\n",
    "    for layer_id in range(layer_num):\n",
    "        layer_neuron_activations = []\n",
    "        for head_id in range(head_num):\n",
    "            head_neuron_activations = []\n",
    "            for j in range(head_dim):   # 一个头\n",
    "                # 获取 Q 的第 j 列\n",
    "                Q_j = Q[sample_id][layer_id][head_id][:, j].reshape(-1, 1)\n",
    "                # 获取 K 的第 j 列\n",
    "                K_j = K[sample_id][layer_id][head_id][:, j].reshape(1, -1)\n",
    "                # 通过矩阵乘法，得到一个人工神经元\n",
    "                neuron = np.matmul(Q_j, K_j)\n",
    "                # 激活值\n",
    "                neuron_activation = np.mean(neuron)\n",
    "                # 将每个神经元激活值添加到头激活矩阵\n",
    "                head_neuron_activations.append(neuron_activation)\n",
    "\n",
    "            layer_neuron_activations.append(head_neuron_activations)\n",
    "            del head_neuron_activations\n",
    "\n",
    "        sample_neuron_activations.append(layer_neuron_activations)\n",
    "        del layer_neuron_activations\n",
    "        \n",
    "sample_neuron_activations_np = np.array(sample_neuron_activations)\n",
    "sample_neuron_activations_np_reshape = sample_neuron_activations_np.reshape(sample_num, layer_num * head_num * head_dim)\n",
    "\n",
    "save_dir = f\"result_new/{movie}/qk\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    print(f\"Directory {save_dir} create\")\n",
    "\n",
    "save_path = os.path.join(save_dir, f'{modality}_qk.npy')\n",
    "\n",
    "np.save(save_path, sample_neuron_activations_np_reshape)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wxl_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
