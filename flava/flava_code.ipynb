{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出结果有误的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import FlavaTextModel, FlavaProcessor\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 1. ==========加载模型和分词器==========\n",
    "model_name = \"C:/Users/xinlong/Desktop/code/python/flava_use/model/facebook/flava-full\"\n",
    "\n",
    "model = FlavaTextModel.from_pretrained(model_name)\n",
    "tokenizer = FlavaProcessor.from_pretrained(model_name)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"模型已加载至 {device}\")\n",
    "# 2. ==========准备输入文本==========\n",
    "texts = [\n",
    "    \"一只函数的返回大幅改进企鹅瑞华企鹅舞i意见猫\", \n",
    "    \"一只猫和一啊但是发射点发射点只狗\", \n",
    "    \"as阿凡达发hpoerujhiopertfasfa\", \n",
    "    \"放噶撒旦发射覅殴打事件回顾i哦速度返回结果点\"\n",
    "]  # 示例输入，替换为你的m个文本\n",
    "\n",
    "inputs = tokenizer(\n",
    "    text=texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ").to(device)\n",
    "# 3. ==========定义一个钩子函数来捕获中间值==========\n",
    "q_list = [[] for _ in range(len(model.encoder.layer))]  # 存储每一层的Q\n",
    "k_list = [[] for _ in range(len(model.encoder.layer))]  # 存储每一层的K\n",
    "ffn_output_list = [[] for _ in range(len(model.encoder.layer))]  # 存储每一层的FFN输出\n",
    "\n",
    "def get_q_hook(layer_idx):\n",
    "    def hook(module, input, output):\n",
    "        q_list[layer_idx].append(output.detach().cpu().numpy())\n",
    "    return hook\n",
    "    \n",
    "\n",
    "def get_k_hook(layer_idx):\n",
    "    def hook(module, input, output):\n",
    "        k_list[layer_idx].append(output.detach().cpu().numpy())\n",
    "    return hook\n",
    "\n",
    "def get_ffn_hook(layer_idx):\n",
    "    def hook(module, input, output):\n",
    "        ffn_output_list[layer_idx].append(output.detach().cpu().numpy())\n",
    "    return hook\n",
    "# 4. ==========注册钩子函数==========\n",
    "for i, layer in enumerate(model.encoder.layer):\n",
    "    layer.attention.attention.query.register_forward_hook(get_q_hook(i))\n",
    "    layer.attention.attention.key.register_forward_hook(get_k_hook(i))\n",
    "    layer.output.register_forward_hook(get_ffn_hook(i))\n",
    "# 5. ==========获取模型输出==========\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "# 6. ==========保存所有数据为NumPy数组==========\n",
    "output_dir = \"./flava_full_outputs\"\n",
    "import os\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "# 保存Q、K和FFN输出\n",
    "for i in range(len(model.encoder.layer)):\n",
    "    # 保存Q\n",
    "    np.save(f'{output_dir}/q_layer_{i+1}.npy', np.array(q_list[i]))\n",
    "    # 保存K\n",
    "    np.save(f'{output_dir}/k_layer_{i+1}.npy', np.array(k_list[i]))\n",
    "    # 保存FFN输出\n",
    "    np.save(f'{output_dir}/ffn_output_layer_{i+1}.npy', np.array(ffn_output_list[i]))\n",
    "print(f\"所有中间值已保存至 {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSeek提供的原始的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import FlavaModel\n",
    "\n",
    "def capture_flava_activations(model):\n",
    "    # 存储钩子的引用\n",
    "    hooks = []\n",
    "    \n",
    "    # 存储各层的数据\n",
    "    attention_data = {}  # 保存每层的Q和K\n",
    "    ffn_outputs = {}     # 保存每层FFN的输出\n",
    "    ffn_weights = {}     # 保存每层FFN的线性层权重\n",
    "\n",
    "    # 遍历模型的encoder层（以image_model为例）\n",
    "    encoder = model.image_model.encoder\n",
    "    for layer_idx, layer in enumerate(encoder.layer):\n",
    "        # 获取当前层的SelfAttention模块\n",
    "        self_attention = layer.attention.attention\n",
    "        \n",
    "        # 注册钩子捕获Q和K\n",
    "        def q_hook(module, input, output, idx=layer_idx):\n",
    "            attention_data.setdefault(idx, {})['Q'] = output.detach()\n",
    "        hook_q = self_attention.query.register_forward_hook(q_hook)\n",
    "        hooks.append(hook_q)\n",
    "        \n",
    "        def k_hook(module, input, output, idx=layer_idx):\n",
    "            attention_data.setdefault(idx, {})['K'] = output.detach()\n",
    "        hook_k = self_attention.key.register_forward_hook(k_hook)\n",
    "        hooks.append(hook_k)\n",
    "        \n",
    "        # 保存FFN的权重（中间层和输出层）\n",
    "        intermediate_weights = layer.intermediate.dense.weight.data.clone()\n",
    "        output_weights = layer.output.dense.weight.data.clone()\n",
    "        ffn_weights[layer_idx] = {\n",
    "            'intermediate': intermediate_weights,\n",
    "            'output': output_weights\n",
    "        }\n",
    "        \n",
    "        # 注册钩子捕获FFN的输出（FlavaOutput的输出）\n",
    "        def ffn_hook(module, input, output, idx=layer_idx):\n",
    "            ffn_outputs[idx] = output.detach()\n",
    "        hook_ffn = layer.output.register_forward_hook(ffn_hook)\n",
    "        hooks.append(hook_ffn)\n",
    "    \n",
    "    return hooks, attention_data, ffn_outputs, ffn_weights\n",
    "\n",
    "# 使用示例\n",
    "model = FlavaModel.from_pretrained(\"facebook/flava-full\")  # 加载模型\n",
    "\n",
    "# 注册钩子\n",
    "hooks, attention_data, ffn_outputs, ffn_weights = capture_flava_activations(model)\n",
    "\n",
    "# 准备输入数据（示例）\n",
    "inputs = {\n",
    "    \"pixel_values\": torch.randn(1, 3, 224, 224),  # 示例图像输入\n",
    "    \"input_ids\": torch.randint(0, 30522, (1, 77)), # 示例文本输入\n",
    "}\n",
    "\n",
    "# 前向传播，触发钩子\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 移除钩子\n",
    "for hook in hooks:\n",
    "    hook.remove()\n",
    "\n",
    "# 打印结果示例\n",
    "print(\"Q values for layer 0:\", attention_data[0]['Q'].shape)\n",
    "print(\"FFN output for layer 0:\", ffn_outputs[0].shape)\n",
    "print(\"FFN intermediate weights shape:\", ffn_weights[0]['intermediate'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改的DeepSeek的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已加载至 cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev\\Anaconda3\\envs\\wxl_transformer\\lib\\site-packages\\transformers\\modeling_utils.py:1072: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 输出结果维度（层数，1，样本数，tokens数，hidden_size）\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import FlavaModel, FlavaProcessor\n",
    "\n",
    "\n",
    "# 0. ==========定义钩子==========\n",
    "def capture_flava_activations(model):\n",
    "    # 存储钩子的引用\n",
    "    hooks = []\n",
    "\n",
    "    # 遍历模型的encoder层（以image_model为例）\n",
    "    encoder = model.text_model.encoder\n",
    "    \n",
    "    # 存储各层的数据\n",
    "    q_list = [[] for _ in range(len(encoder.layer))]  # 保存每层的Q和K\n",
    "    k_list = [[] for _ in range(len(encoder.layer))]  # 保存每层的Q和K\n",
    "    ffn_outputs = [[] for _ in range(len(encoder.layer))]    # 保存每层FFN的输出\n",
    "    ffn_weights = {}     # 保存每层FFN的线性层权重\n",
    "\n",
    "\n",
    "    for layer_idx, layer in enumerate(encoder.layer):\n",
    "        # 获取当前层的SelfAttention模块\n",
    "        self_attention = layer.attention.attention\n",
    "        \n",
    "        # 注册钩子捕获Q和K\n",
    "        def q_hook(module, input, output, idx=layer_idx):\n",
    "            q_list[idx].append(output.detach().cpu().numpy())\n",
    "        hook_q = self_attention.query.register_forward_hook(q_hook)\n",
    "        hooks.append(hook_q)\n",
    "        \n",
    "        def k_hook(module, input, output, idx=layer_idx):\n",
    "            k_list[idx] = output.detach()\n",
    "        hook_k = self_attention.key.register_forward_hook(k_hook)\n",
    "        hooks.append(hook_k)\n",
    "        \n",
    "        # 保存FFN的权重（中间层和输出层）\n",
    "        intermediate_weights = layer.intermediate.dense.weight.data.clone()\n",
    "        output_weights = layer.output.dense.weight.data.clone()\n",
    "        ffn_weights[layer_idx] = {\n",
    "            'intermediate': intermediate_weights,\n",
    "            'output': output_weights\n",
    "        }\n",
    "        \n",
    "        # 注册钩子捕获FFN的输出（FlavaOutput的输出）\n",
    "        def ffn_hook(module, input, output, idx=layer_idx):\n",
    "            ffn_outputs[idx] = output.detach().cpu().numpy()\n",
    "        hook_ffn = layer.output.register_forward_hook(ffn_hook)\n",
    "        hooks.append(hook_ffn)\n",
    "    \n",
    "    return hooks, q_list, k_list, ffn_outputs, ffn_weights\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_name = \"C:/Users/xinlong/Desktop/code/python/flava_use/model/facebook/flava-full\"\n",
    "\n",
    "    # 设置设备\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # 1. ==========加载模型和分词器==========\n",
    "    model = FlavaModel.from_pretrained(model_name)  # 加载模型\n",
    "    tokenizer = FlavaProcessor.from_pretrained(model_name)\n",
    "\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    print(f\"模型已加载至 {device}\")\n",
    "\n",
    "\n",
    "    # 2. ==========准备输入文本==========\n",
    "    texts = [\n",
    "        \"一只函数的返回大幅改进企鹅瑞华企鹅舞i意见猫\", \n",
    "        \"一只猫和一啊但是发射点发射点只狗\", \n",
    "        \"as阿凡达发hpoerujhiopertfasfa\", \n",
    "        \"放噶撒旦发射覅殴打事件回顾i哦速度返回结果点\"\n",
    "    ]\n",
    "    inputs = tokenizer(\n",
    "        text=texts, \n",
    "        return_tensors=\"pt\", \n",
    "        padding=True, \n",
    "        truncation=True\n",
    "    ).to(device)\n",
    "\n",
    "\n",
    "    # 3. ==========注册钩子==========\n",
    "    hooks, q_list, k_list, ffn_outputs, ffn_weights = capture_flava_activations(model)\n",
    "\n",
    "\n",
    "    # 4. ==========前向传播，触发钩子==========\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "\n",
    "    # 5. ==========移除钩子==========\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "\n",
    "    # # 打印结果示例\n",
    "    # print(\"Q values for layer 0:\", attention_data[0]['Q'].shape)\n",
    "    # print(\"FFN output for layer 0:\", ffn_outputs[0].shape)\n",
    "    # print(\"FFN intermediate weights shape:\", ffn_weights[0]['intermediate'].shape)\n",
    "\n",
    "    # # 6. ==========保存所有数据为NumPy数组==========\n",
    "    # output_dir = \"./flava_full_outputs\"\n",
    "    # import os\n",
    "    # if not os.path.exists(output_dir):\n",
    "    #     os.makedirs(output_dir)\n",
    "\n",
    "    # # 保存Q、K和FFN输出\n",
    "    # for i in range(len(model.text_model.encoder.layer)):\n",
    "    #     # 保存Q\n",
    "    #     np.save(f'{output_dir}/q_layer_{i+1}.npy', np.array(q_list[i]))\n",
    "\n",
    "    # ffn_outputs_np = np.array(ffn_outputs)\n",
    "    # print(ffn_outputs_np.shape)\n",
    "\n",
    "\n",
    "    # import gc   # 清理内存\n",
    "    # gc.collect()    # 清理内存\n",
    "    # del q_list, k_list, ffn_outputs, ffn_weights\n",
    "    # torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4, 24, 768)\n",
      "[ 1.70472309e-01  1.53833896e-01  3.94382179e-01 -1.61612034e-01\n",
      "  2.59675264e-01 -2.44080603e-01 -1.14520989e-01  1.69595867e-01\n",
      " -1.54785067e-01  9.13730264e-02 -5.52020147e-02  4.09352481e-02\n",
      "  5.27053401e-02  1.15245104e-01  4.80525158e-02 -5.11678904e-02\n",
      " -2.87483037e-02  2.91853040e-01  4.31904256e-01  3.16732019e-01\n",
      " -9.49063897e-03 -1.01475067e-01 -8.95549357e-03 -1.16956249e-01\n",
      " -1.24302559e-01  1.82863384e-01 -1.62635408e-02  2.66659379e-01\n",
      "  8.08232725e-02  1.26410842e-01 -1.33667633e-01  2.68276483e-02\n",
      " -3.19827348e-03 -2.37897098e-01 -4.32671607e-02  1.25211611e-01\n",
      " -5.86714447e-02 -4.15027998e-02 -1.54236071e-02  3.01429987e-01\n",
      "  2.98926849e-02  2.35183388e-01 -3.69920619e-02  1.10269353e-01\n",
      "  1.63826346e-01 -1.72405988e-01 -1.12857103e-01  8.36321637e-02\n",
      "  6.42416775e-02 -4.73584384e-02  1.35626584e-01 -9.32509080e-02\n",
      " -1.77340865e-01  3.16753276e-02  1.55827141e+00 -1.42473578e-02\n",
      " -9.12624523e-02  6.41826838e-02 -8.21418017e-02 -1.20944738e-01\n",
      " -5.17833233e-02  9.32705551e-02 -1.96326613e-01  4.45601158e-02\n",
      " -8.52554291e-02  2.13384569e-01 -1.49886429e-01  3.38382423e-01\n",
      "  1.00539647e-01  1.23595156e-01 -1.06843032e-01 -6.94072992e-02\n",
      "  1.27422139e-02 -6.78788275e-02 -9.86301452e-02  5.72337210e-02\n",
      "  1.75077572e-01  8.08461756e-02  1.55894175e-01  1.47737160e-01\n",
      " -9.45491642e-02  8.29111785e-02  8.64255130e-02 -8.95375460e-02\n",
      "  1.63359806e-01 -7.97592774e-02 -1.73284382e-01  6.13970459e-02\n",
      "  2.50608474e-02 -3.32104057e-01 -2.39242792e-01  6.01684511e-01\n",
      " -5.03566563e-02  1.38877630e-01  2.45076418e-03  9.37620550e-03\n",
      " -1.54334366e-01  1.03021711e-01  6.46316707e-02 -1.81978121e-01\n",
      "  3.08864042e-02 -1.36668831e-01  6.45736530e-02 -1.01065286e-01\n",
      "  6.55124150e-03 -1.21896006e-01 -3.05487752e-01 -1.45098627e-01\n",
      "  1.24410763e-01 -1.62566453e-01 -1.52322799e-02  1.27061084e-01\n",
      "  2.05662832e-01  6.33742809e-02  1.37822285e-01  9.30846930e-02\n",
      "  8.75682905e-02 -1.95234597e-01  2.75872797e-01  3.04201469e-02\n",
      "  4.94679585e-02 -6.58799267e+00 -6.38516918e-02 -9.75464508e-02\n",
      "  8.12333524e-02 -1.56887751e+01  3.28315198e-02 -2.78852701e-01\n",
      "  1.40997678e-01  6.57214597e-02  1.93683431e-01  5.87419830e-02\n",
      " -2.86109835e-01  1.31677166e-01  3.72978985e-01 -1.55562818e-01\n",
      " -2.22301990e-01  4.27234843e-02  4.00386155e-01  1.79913521e-01\n",
      "  3.01015377e-02 -6.74424395e-02  2.19226927e-01  2.27861777e-01\n",
      " -1.19007552e+00  1.15169764e-01 -4.20446098e-02  1.59763172e-02\n",
      " -1.89467296e-01  3.93688679e-04 -2.78861225e-02 -9.74421576e-02\n",
      " -1.06188655e-01  7.63361156e-03  6.38161823e-02 -1.79618567e-01\n",
      "  6.07451424e-03  1.56275362e-01 -3.40400934e-01 -1.99013859e-01\n",
      "  3.30110639e-02  1.06573403e-02 -1.41674548e-01 -6.35197908e-02\n",
      "  5.05877770e-02  1.74521059e-02  9.39936787e-02  2.96251476e-03\n",
      "  5.48350289e-02 -9.18064937e-02 -1.81157857e-01  5.64363152e-02\n",
      "  1.18384719e+00  1.31571174e-01 -9.60665196e-02  1.31384060e-01\n",
      "  1.93450511e-01  1.47686064e-01 -5.30674085e-02  2.39161447e-01\n",
      " -9.45453942e-02  3.16705316e-01  8.94195735e-02 -2.10690722e-02\n",
      "  2.42878627e-02  1.58661783e-01 -1.40304029e-01 -2.72931397e-01\n",
      " -3.40134054e-02 -1.64205685e-01 -4.25320268e-02 -4.10337269e-01\n",
      " -1.97487101e-02  6.20685741e-02  1.97576672e-01 -1.26025081e-01\n",
      "  2.75483727e-03 -1.78460088e-02  5.74524701e-03 -1.04971148e-01\n",
      " -2.32771203e-01 -7.21365213e-05  8.16805810e-02  7.37100244e-02\n",
      "  1.80276752e-01  1.87941507e-01 -9.12372470e-02 -1.19952314e-01\n",
      " -2.53247052e-01 -9.45686400e-02  1.81291953e-01 -2.92846560e-03\n",
      " -2.89352685e-01  5.29747725e-01  4.70737219e-02  1.56422555e-01\n",
      "  4.24214453e-02  1.04189947e-01 -1.79064050e-02  1.09104495e-02\n",
      "  1.06785022e-01  7.03512356e-02  5.24788164e-02 -5.49835637e-02\n",
      "  2.13680208e-01  7.50941485e-02  5.67679405e-02  3.55184674e-02\n",
      "  6.32755235e-02  2.42947400e-01  1.62764251e-01 -2.74217606e-01\n",
      "  4.40578684e-02  2.03884616e-02  2.06914186e-01  5.90905808e-02\n",
      " -1.51732981e-01  2.43647337e-01 -2.71558687e-02  7.38684833e-02\n",
      " -2.37601012e-01  2.40818799e-01 -2.38341987e-01  1.91577017e-01\n",
      "  2.42297694e-01  2.31371939e-01 -2.44366705e-01 -3.52319293e-02\n",
      "  3.58195424e-01 -6.80752695e-02  2.34786451e-01  8.89074206e-02\n",
      "  2.38012046e-01  5.37150800e-02 -9.41750035e-02 -1.14917219e-01\n",
      " -3.76636498e-02  7.04568401e-02  2.89457515e-02 -4.64663841e-02\n",
      "  3.22448403e-01  1.09235942e+00  4.23109308e-02 -1.42002583e-01\n",
      " -1.31281838e-01  1.01531386e-01 -1.03168115e-01 -2.23643892e-02\n",
      "  4.02105153e-02 -5.19220568e-02 -3.50554027e-02  1.93682551e-01\n",
      " -4.73207794e-03 -2.41984829e-01 -1.15415446e-01  2.27374002e-01\n",
      " -2.25545466e-01  1.17666006e-01  7.11423382e-02 -1.51226059e-01\n",
      "  1.76643327e-01  4.17165160e-02 -2.47021049e-01 -5.83395660e-02\n",
      "  3.20827439e-02  2.38550782e-01  1.20190285e-01 -4.02637944e-02\n",
      " -7.63882846e-02 -2.24828929e-01 -7.78587088e-02  1.29653484e-01\n",
      "  2.25610256e-01 -1.15771040e-01  1.31845504e-01 -1.10826120e-01\n",
      " -2.04483405e-01  1.47735938e-01  6.79576024e-02 -6.42229468e-02\n",
      "  6.37945235e-02 -6.58337474e-02  2.03981802e-01 -2.38839537e-01\n",
      "  6.46599531e-02  2.93205470e-01 -7.53107220e-02  3.58955488e-02\n",
      "  7.78075457e-02 -4.55433190e-01  1.20590992e-01 -1.56948745e-01\n",
      "  8.34484771e-02 -8.53525624e-02 -2.96416208e-02  1.87059343e-01\n",
      "  1.10859290e-01 -1.23833694e-01 -3.46439242e-01  1.34117618e-01\n",
      " -3.20062786e-03  2.58079261e-01 -2.47295350e-01  2.88707521e-02\n",
      " -1.92426458e-01 -2.44144812e-01  1.24431573e-01  2.14149088e-01\n",
      " -2.98389673e-01 -1.98825747e-02 -1.19143054e-02 -6.97332546e-02\n",
      " -6.43546879e-03  1.59752443e-02  6.27385527e-02  1.13431863e-01\n",
      "  1.16096847e-01  6.97654560e-02 -9.15940013e-03  1.29273623e-01\n",
      "  2.93583751e-01  2.02263653e-01  3.32412757e-02  2.16943964e-01\n",
      "  2.82505095e-01 -4.09054011e-03 -4.54369262e-02 -2.33496875e-01\n",
      " -4.48571630e-02 -1.14729375e-01 -1.66191712e-01  3.64371777e-01\n",
      " -1.83301568e-01  1.23165451e-01 -1.20287128e-01 -8.15943554e-02\n",
      "  6.66815117e-02  2.77454108e-02 -3.77996057e-01 -1.10004261e-01\n",
      " -1.41849339e-01 -1.48774117e-01  2.27405846e-01  9.63412598e-02\n",
      " -1.97717160e-01  5.67225926e-02 -1.86793655e-01 -2.92105023e-02\n",
      "  1.72117501e-01  2.23673210e-01  1.51651472e-01  1.48262009e-02\n",
      "  3.53743136e-03  8.62343833e-02  1.72558591e-01  4.21798080e-02\n",
      "  1.69682026e-01 -2.22721845e-01 -3.95901501e-04 -8.58690515e-02\n",
      " -1.33575052e-02  5.94795868e-02  3.89801040e-02 -2.00136632e-01\n",
      " -4.49338555e-01 -1.33249685e-01 -7.13988394e-03 -1.37684897e-01\n",
      "  3.22705567e-01  2.71582603e-01 -1.32569596e-01 -4.81324904e-02\n",
      " -1.78046674e-02 -2.20431201e-02  1.34730726e-01 -2.16316819e-01\n",
      " -1.44731626e-01  1.38481081e-01  7.40614086e-02 -9.69398171e-02\n",
      " -2.38068253e-01  1.44054845e-01 -1.26892060e-01 -1.22554243e-01\n",
      "  1.58955574e-01  1.28583372e-01 -2.36242041e-02 -9.78080630e-02\n",
      " -1.36567935e-01  8.27528238e-02 -9.52218324e-02 -3.82500812e-02\n",
      "  8.03773850e-03 -1.34523124e-01  1.43171981e-01 -9.53785181e-02\n",
      " -4.83208969e-02  4.78814021e-02  1.69508263e-01 -2.86218703e-01\n",
      " -8.46489519e-02 -1.52372465e-01 -3.44292149e-02 -5.71640581e-03\n",
      " -5.75398877e-02 -3.07727814e-01 -1.93574913e-02  8.18327144e-02\n",
      "  1.17144212e-02  1.33744657e-01  3.16892713e-02  2.38322988e-02\n",
      " -2.48138368e-01  1.33812174e-01  5.11790290e-02 -5.36388606e-02\n",
      " -1.85584068e-01  6.13594949e-02  9.75405872e-02 -8.45014229e-02\n",
      "  1.07781492e-01 -9.14680213e-02 -1.07027695e-01 -3.38669643e-02\n",
      "  3.19867581e-01  2.65678465e-01 -4.03430387e-02 -1.55223280e-01\n",
      "  1.04432367e-01 -1.20704621e-01  3.34508531e-02 -3.59589607e-01\n",
      " -2.45891392e-01 -1.35764740e-02  1.03872404e-01  2.58561045e-01\n",
      "  5.64437956e-02 -9.30897668e-02  1.14393122e-01  7.72200525e-03\n",
      " -2.03148723e-02 -4.63794693e-02 -3.87774855e-02 -9.48157758e-02\n",
      "  3.54508489e-01 -1.36291340e-01  1.01355769e-01 -3.20566535e-01\n",
      " -5.56076616e-02  1.74516186e-01  1.90700829e-01 -2.44408548e-01\n",
      "  1.09085567e-01 -1.05841115e-01 -1.29577339e-01 -4.05260660e-02\n",
      " -4.16715704e-02 -7.60256872e-02 -1.68025985e-01 -8.72674361e-02\n",
      "  1.48627758e-02  1.03492498e-01 -3.45615670e-03 -4.47339147e-01\n",
      "  1.42084301e-01  8.67051557e-02  2.06742465e-01  4.26018313e-02\n",
      "  2.87690222e-01 -8.08283091e-02  4.44309860e-02  1.64618082e-02\n",
      "  1.87970251e-02  4.77691859e-01 -5.68300709e-02 -2.14918151e-01\n",
      "  7.14716613e-02  1.10036731e-01 -3.05020586e-02 -2.70852447e-02\n",
      " -2.14126438e-01 -3.77648920e-02 -1.18164472e-01  1.48020804e-01\n",
      " -5.80041930e-02  9.09668803e-02 -6.66380599e-02  7.08438456e-02\n",
      "  3.90241593e-01  7.84727558e-03  2.58693755e-01  3.41895491e-01\n",
      "  6.55246592e+00  8.10178742e-02 -2.37942025e-01 -1.92945778e-01\n",
      " -8.87340903e-02  1.89238340e-02 -3.13484550e-01 -6.08656891e-02\n",
      " -1.37760565e-01  2.90715918e-02  4.30711098e-02  9.78223458e-02\n",
      "  3.87692362e-01 -1.11233965e-02 -1.68101460e-01  1.86566532e-01\n",
      "  1.73859268e-01  2.49956548e-02 -1.05946787e-01 -2.67024823e-02\n",
      " -3.01570177e-01 -7.85261244e-02  6.91290200e-02  1.72464669e-01\n",
      " -1.74886405e-01  7.73742348e-02 -2.19240725e-01 -8.87745321e-02\n",
      "  5.87277859e-02  1.57630160e-01 -3.94358188e-02  1.03423260e-01\n",
      "  1.22481994e-01  1.69794232e-01  1.06835589e-01 -8.02178979e-02\n",
      " -3.49218071e-01  1.25639141e-03  2.42828742e-01 -5.20811677e-02\n",
      " -1.48647234e-01 -1.45269990e-01 -1.33118585e-01  8.16629902e-02\n",
      "  3.43233377e-01 -4.52229455e-02  2.12559149e-01  4.43695532e-03\n",
      " -2.33483255e-01 -9.06680375e-02 -1.40881836e-02 -1.92163095e-01\n",
      " -1.58145279e-01 -1.46089606e-02 -1.79633260e-01 -8.35500360e-02\n",
      " -6.76430389e-02  1.48044556e-01  1.67778775e-01  4.77633253e-02\n",
      "  6.29134402e-02  6.28849119e-02  5.08939862e-01  1.08587161e-01\n",
      " -2.63005942e-02 -4.84637544e-03  1.29469782e-01 -1.55646339e-01\n",
      "  9.62868929e-02  1.89591125e-02  2.76887655e-01  6.01653010e-02\n",
      "  7.00041950e-02 -1.80374116e-01  3.69407088e-02 -1.01390563e-01\n",
      " -8.41978192e-02  1.03504613e-01  8.45125467e-02  2.67377794e-01\n",
      " -1.92286909e-01  1.37627855e-01  1.59845278e-01 -1.13409355e-01\n",
      "  4.19413149e-01  2.62004197e-01 -9.56029892e-02  2.33788341e-01\n",
      " -1.10143304e-01 -4.35802490e-02 -1.21191628e-01  1.55607387e-02\n",
      " -2.37141222e-01  2.15957388e-02 -3.41097414e-01  9.34193507e-02\n",
      " -4.50842083e-04 -8.15371126e-02 -2.21668750e-01 -2.77888775e-03\n",
      " -6.72017112e-02 -4.75501306e-02  1.39238656e-01 -2.78407782e-01\n",
      "  7.46242926e-02 -2.37997818e+01 -2.40593478e-02 -9.72796232e-02\n",
      " -2.46572159e-02  2.16772273e-01 -2.78405368e-01 -2.26861149e-01\n",
      " -1.98897585e-01  7.81561136e-02 -3.48576345e-02  1.78699642e-01\n",
      "  4.22973335e-02 -1.27946317e-01 -2.27046832e-01  1.44806817e-01\n",
      " -7.34571815e-02  2.19403386e-01  3.59364823e-02  2.02130497e-01\n",
      " -4.73391771e-01  1.05634570e-01 -8.25760290e-02 -1.51863888e-01\n",
      " -4.34106514e-02 -8.37925971e-02  2.90912241e-02  2.83281356e-01\n",
      " -1.38517380e-01 -1.20532081e-01 -1.09402567e-01 -2.13354766e-01\n",
      "  3.82851064e-02  3.61793041e-02  6.00551888e-02 -2.28530332e-01\n",
      " -3.50893527e-01  1.23254612e-01  7.39480704e-02  9.26198512e-02\n",
      " -5.60926646e-02  2.29963452e-01 -1.03522867e-01  1.04577333e-01\n",
      " -1.38860315e-01  1.72716185e-01  1.18819535e-01 -6.56183511e-02\n",
      "  1.70973703e-01  7.69853592e-03  5.98879382e-02  3.87524739e-02\n",
      "  6.32896274e-02  2.93578804e-02 -4.61341441e-03  1.04667708e-01\n",
      "  5.32278657e-01  6.44561350e-02  3.40154618e-01  3.57189804e-01\n",
      "  1.77073166e-01  1.04445130e-01 -8.10898989e-02 -2.20041387e-02\n",
      "  6.57213330e-02  5.16535565e-02 -6.44496679e-02  2.05457344e+01\n",
      "  3.91133451e+00 -5.70882391e-03 -5.90006188e-02 -3.01299632e-01\n",
      " -2.82161869e-02  1.47034362e-01 -1.17434949e-01 -8.70122761e-03\n",
      " -5.72591983e-02  1.54796004e-01  2.34761953e-01  7.84244016e-02\n",
      " -1.24584749e-01 -1.45538986e-01  7.90016353e-02  1.24178022e-01\n",
      " -3.64470221e-02  2.38729641e-02  6.46840334e-02  2.65406817e-03\n",
      "  4.44888175e-01  2.29316786e-01  4.87217754e-02  1.27580166e-02\n",
      "  2.81288862e-01  2.31333375e-01  1.82320848e-01 -1.05490781e-01\n",
      " -2.40435719e-01 -2.25402355e-01 -1.82298288e-01  2.67886639e-01\n",
      " -7.37642199e-02 -2.63785213e-01  1.78088427e-01  2.48790346e-03\n",
      "  1.51811093e-01  9.03330445e-02  1.06058024e-01 -1.68275684e-01\n",
      "  1.30911186e-01  3.00502151e-01  4.09597307e-02 -7.64232427e-02\n",
      "  5.81178367e-02 -8.52613226e-02  3.28978598e-01  1.42717421e-01\n",
      "  1.03059500e-01 -6.28932044e-02 -2.23030597e-02 -1.41928159e-03\n",
      "  5.52033223e-02  1.13802135e-01 -5.93113154e-02  1.32464170e-01\n",
      "  1.24931484e-02  1.09864533e-01 -3.25572312e-01 -1.99691802e-02\n",
      "  4.67939824e-02  1.51433140e-01 -1.40146405e-01 -2.90281624e-02\n",
      " -8.12038220e-03 -7.46095553e-02 -1.01267457e-01  4.92425114e-02\n",
      "  1.93793967e-01  3.31885010e-01  6.18907884e-02  5.49246520e-02\n",
      "  7.18031824e-02 -1.82604462e-01  3.30896080e-02 -9.40171033e-02\n",
      " -2.60684639e-01  2.42175728e-01  2.14024872e-01 -1.95557606e+00\n",
      " -4.81301770e-02  4.26407829e-02 -1.51573345e-01 -3.14980328e-01]\n"
     ]
    }
   ],
   "source": [
    "# q_list_np = np.array(q_list)\n",
    "ffn_outputs_np = np.array(ffn_outputs)\n",
    "print(ffn_outputs_np.shape)\n",
    "print(ffn_outputs_np[0][0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wxl_transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
